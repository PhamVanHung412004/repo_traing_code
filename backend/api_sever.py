from flask import Flask, request, jsonify
from flask_cors import CORS
from typing import (
    Dict
)
import re
import pickle
import time
from sklearn.base import BaseEstimator, TransformerMixin
import numpy as np
import csv

# C·∫•u h√¨nh CORS cho domain c·ª• th·ªÉ
CORS_ORIGINS = [
    "https://trang-nguyen-hoi-be.btecit.tech",
    "http://trang-nguyen-hoi-be.btecit.tech",
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "http://localhost:5000",
    "http://127.0.0.1:5000",
    "http://localhost:8000",
    "http://127.0.0.1:8000"
]


class EmailFeatures(BaseEstimator, TransformerMixin):
    """Tr√≠ch xu·∫•t c√°c ƒë·∫∑c tr∆∞ng b·ªï sung t·ª´ email"""
    def fit(self, X, y=None):
        return self
    
    def transform(self, X):
        features = []
        for text in X:
            feat = {
                'length': len(text),
                'num_exclamation': text.count('!'),
                'num_question': text.count('?'),
                'num_caps': sum(1 for c in text if c.isupper()),
                'caps_ratio': sum(1 for c in text if c.isupper()) / (len(text) + 1),
                'has_url': 1 if 'http' in text.lower() or 'www' in text.lower() else 0,
                'has_email': 1 if '@' in text else 0,
                'num_special_chars': len(re.findall(r'[!@#$%^&*()]', text)),
                'num_currency': len(re.findall(r'[$‚Ç´¬•‚Ç¨¬£]', text)),
                'has_discount_words': 1 if any(word in text.lower() for word in 
                    ['gi·∫£m gi√°', 'khuy·∫øn m√£i', 'sale', 'free', 'mi·ªÖn ph√≠']) else 0
            }
            features.append(list(feat.values()))
        return np.array(features)

def preprocess_text(text):
    """Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n ti·∫øng Vi·ªát"""
    # Lo·∫°i b·ªè HTML tags
    text = re.sub(r'<.*?>', '', text)
    # Lo·∫°i b·ªè URLs
    text = re.sub(r'http\S+|www.\S+', '', text)
    # Lo·∫°i b·ªè email addresses
    text = re.sub(r'\S+@\S+', '', text)
    # Lo·∫°i b·ªè s·ªë ƒëi·ªán tho·∫°i
    text = re.sub(r'\d{10,}', '', text)
    # Chu·∫©n h√≥a kho·∫£ng tr·∫Øng
    text = re.sub(r'\s+', ' ', text)
    return text.lower().strip()

def predict_email(text, model):
    """D·ª± ƒëo√°n lo·∫°i email"""
    processed_text = preprocess_text(text)
    prediction = model.predict([processed_text])[0]
    probabilities = model.predict_proba([processed_text])[0]
    
    return {
        'prediction': prediction,
        'confidence': max(probabilities),
        'probabilities': dict(zip(model.classes_, probabilities))
    }



app = Flask(__name__)

# C·∫•u h√¨nh CORS v·ªõi middleware
CORS(app, 
     origins=CORS_ORIGINS,
     allow_credentials=True,
     methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
     allow_headers=["Content-Type", "Authorization", "X-Requested-With", "X-Total-Count"],
     expose_headers=["Content-Type", "X-Total-Count"]
)

# Global variables for statistics
request_count = 0
prediction_stats = {}

with open("model/improved_email_classifier.pkl", "rb") as f:
    model = pickle.load(f)

@app.route('/email', methods=['POST'])
def chat():
    global request_count, prediction_stats
    
    # L·∫•y d·ªØ li·ªáu t·ª´ request v√† ƒë·∫£m b·∫£o an to√†n
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Invalid JSON data"}), 400
        
        message = data.get('message', '')
        if not message:
            return jsonify({"error": "Message field is required"}), 400
            
    except Exception as e:
        print(f"‚ùå Error parsing request data: {e}")
        return jsonify({"error": "Invalid request data format"}), 400
    
    # Update statistics
    request_count += 1
    prediction = predict_email(message, model)
    
    # Update prediction statistics
    pred_type = prediction['prediction']
    if pred_type not in prediction_stats:
        prediction_stats[pred_type] = 0
    prediction_stats[pred_type] += 1
    
    # Log request details
    print(f"üìß Email Analysis Request #{request_count}:")
    print(f"   üìù Content length: {len(message)} characters")
    print(f"   üìÖ Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"   üéØ Prediction: {prediction['prediction']}")
    print(f"   üìä Confidence: {prediction['confidence']:.2%}")
    print(f"   üìà Probabilities: {prediction['probabilities']}")
    print(f"   üìä Total requests: {request_count}")
    print(f"   üìà Prediction stats: {prediction_stats}")
    print("-" * 50)
    
    return jsonify(prediction), 200

@app.route('/stats', methods=['GET'])
def get_stats():
    """Get API statistics"""
    return jsonify({
        "total_requests": request_count,
        "prediction_stats": prediction_stats,
        "server_uptime": time.strftime('%Y-%m-%d %H:%M:%S')
    }), 200

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
        "model_loaded": model is not None,
        "cors_origins": CORS_ORIGINS,
        "allowed_methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
        "allowed_headers": ["Content-Type", "Authorization", "X-Requested-With", "X-Total-Count"]
    }), 200

@app.route('/csv', methods=['GET'])
def get_csv_rows():
    """Tr·∫£ v·ªÅ m·ªôt ph·∫ßn d·ªØ li·ªáu t·ª´ file CSV v·ªõi ph√¢n trang"""
    try:
        offset = int(request.args.get('offset', 0))
        limit = int(request.args.get('limit', 10))
    except ValueError:
        return jsonify({"error": "Invalid offset or limit"}), 400

    csv_path = "database/data.csv"
    rows = []
    total = 0
    try:
        with open(csv_path, newline='', encoding='utf-8') as csvfile:
            reader = csv.reader(csvfile)
            all_rows = list(reader)
            total = len(all_rows)
            rows = all_rows[offset:offset+limit]
    except Exception as e:
        return jsonify({"error": f"Could not read CSV: {e}"}), 500

    return jsonify({
        "rows": rows,
        "offset": offset,
        "limit": limit,
        "total": total
    }), 200

@app.route('/show_csv', methods=['GET'])
def show_csv():
    csv_path = "database/data.csv"
    rows = []
    try:
        with open(csv_path, newline='', encoding='utf-8') as csvfile:
            reader = list(csv.reader(csvfile))
            rows = reader
    except Exception as e:
        return f"<h3>L·ªói ƒë·ªçc file CSV: {e}</h3>", 500

    # T·∫°o HTML b·∫£ng
    html = "<h2>B·∫£ng d·ªØ li·ªáu CSV</h2><table border='1' style='border-collapse:collapse;'>"
    for i, row in enumerate(rows):
        html += "<tr>"
        for cell in row:
            if i == 0:
                html += f"<th>{cell}</th>"
            else:
                html += f"<td>{cell}</td>"
        html += "</tr>"
    html += "</table>"
    return html

@app.route('/', methods=['GET'])
def root():
    """Root endpoint with CORS information"""
    return jsonify({
        "message": "Email Classification API",
        "cors_enabled": True,
        "allowed_origins": CORS_ORIGINS,
        "endpoints": {
            "email_classification": "/email",
            "health_check": "/health",
            "statistics": "/stats"
        },
        "status": "running"
    }), 200

if __name__ == '__main__':
    # B·∫≠t ch·∫ø ƒë·ªô debug ƒë·ªÉ t·ª± ƒë·ªông reload khi c√≥ thay ƒë·ªïi code
    app.run(
        host='0.0.0.0',  # Cho ph√©p truy c·∫≠p t·ª´ b√™n ngo√†i
        port=5000,
        debug=True,      # B·∫≠t ch·∫ø ƒë·ªô debug v√† auto-reload
        use_reloader=True,  # ƒê·∫£m b·∫£o reloader ƒë∆∞·ª£c b·∫≠t
        threaded=True    # Cho ph√©p x·ª≠ l√Ω nhi·ªÅu request ƒë·ªìng th·ªùi
    )